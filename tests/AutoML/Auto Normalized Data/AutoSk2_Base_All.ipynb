{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto-Sklearn2 Classifier (3GB RAM)\n",
    "Data preprocessed with built-in normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40180, 1)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../../\")\n",
    "\n",
    "import modules\n",
    "import numpy as np\n",
    "from sklearn import model_selection\n",
    "from autosklearn.experimental.askl2 import AutoSklearn2Classifier\n",
    "\n",
    "mydata = modules.NT()\n",
    "x_train, x_val, x_test, y_train, y_val, y_test = mydata.createSets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AutoSklearn2Classifier(metric=accuracy, n_jobs=-1, per_run_time_limit=24,\n",
       "                       time_left_for_this_task=60)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = AutoSklearn2Classifier(time_left_for_this_task=60, n_jobs=-1)\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9915824915824916\n",
      "[2. 5. 3. 5. 3. 6. 6. 5. 2. 6. 3. 5. 4. 4. 6. 6. 2. 3. 3. 1. 3. 6. 4. 1.\n",
      " 3. 4. 5. 3. 1. 2. 1. 5. 3. 4. 2. 4. 3. 3. 2. 2. 2. 5. 2. 4. 5. 1. 1. 5.\n",
      " 3. 2. 4. 5. 3. 2. 4. 2. 6. 5. 4. 4. 3. 4. 1. 6. 4. 6. 3. 6. 2. 2. 3. 4.\n",
      " 4. 5. 1. 1. 2. 6. 6. 2. 1. 3. 1. 5. 1. 6. 6. 2. 3. 5. 2. 4. 4. 5. 4. 3.\n",
      " 1. 5. 3. 2. 3. 3. 6. 1. 2. 3. 6. 6. 5. 2. 3. 6. 6. 6. 2. 3. 1. 6. 4. 5.\n",
      " 3. 4. 6. 1. 3. 1. 6. 4. 1. 4. 1. 5. 4. 5. 4. 5. 6. 5. 3. 6. 5. 5. 6. 3.\n",
      " 1. 2. 5. 6. 6. 5. 6. 2. 3. 1. 6. 2. 6. 3. 3. 3. 2. 4. 3. 3. 2. 3. 5. 5.\n",
      " 1. 1. 6. 4. 2. 6. 6. 1. 2. 1. 3. 1. 6. 2. 5. 4. 6. 4. 5. 1. 1. 3. 6. 6.\n",
      " 1. 6. 4. 2. 4. 2. 6. 1. 1. 2. 3. 2. 3. 5. 2. 4. 2. 2. 4. 5. 6. 5. 4. 3.\n",
      " 3. 1. 5. 1. 4. 3. 1. 2. 4. 2. 5. 2. 3. 3. 2. 5. 1. 6. 3. 3. 6. 2. 4. 3.\n",
      " 1. 4. 5. 4. 6. 2. 2. 2. 3. 1. 2. 4. 6. 3. 1. 3. 1. 5. 3. 5. 1. 4. 6. 6.\n",
      " 4. 2. 1. 1. 3. 1. 3. 2. 2. 3. 6. 1. 2. 5. 3. 5. 4. 6. 1. 2. 3. 5. 1. 2.\n",
      " 3. 3. 6. 6. 5. 4. 5. 3. 1. 3. 6. 6. 2. 3. 4. 3. 6. 5. 2. 4. 3. 1. 5. 4.\n",
      " 6. 3. 5. 2. 6. 6. 3. 4. 3. 3. 6. 1. 1. 5. 5. 4. 3. 6. 2. 4. 2. 4. 3. 4.\n",
      " 1. 2. 6. 4. 6. 3. 2. 5. 2. 1. 5. 3. 4. 6. 1. 4. 5. 6. 2. 4. 3. 5. 5. 4.\n",
      " 4. 2. 4. 5. 5. 4. 3. 3. 6. 4. 2. 4. 4. 3. 3. 4. 5. 3. 2. 3. 3. 3. 5. 2.\n",
      " 5. 2. 6. 2. 4. 6. 2. 4. 4. 3. 1. 5. 5. 5. 5. 4. 4. 6. 6. 1. 2. 1. 6. 2.\n",
      " 3. 2. 1. 4. 5. 5. 2. 6. 4. 6. 6. 2. 4. 6. 5. 1. 6. 5. 3. 5. 5. 4. 2. 1.\n",
      " 6. 1. 5. 2. 6. 6. 5. 1. 1. 5. 4. 2. 1. 6. 3. 4. 2. 5. 2. 1. 5. 1. 4. 4.\n",
      " 1. 5. 6. 1. 6. 3. 3. 3. 1. 2. 6. 5. 4. 3. 5. 1. 6. 6. 1. 1. 2. 4. 2. 1.\n",
      " 6. 2. 3. 4. 6. 1. 6. 3. 1. 4. 6. 1. 5. 3. 1. 4. 4. 4. 1. 4. 2. 4. 5. 5.\n",
      " 6. 3. 2. 3. 4. 2. 5. 3. 5. 1. 5. 1. 2. 4. 3. 3. 5. 4. 1. 3. 1. 6. 6. 5.\n",
      " 6. 5. 6. 5. 3. 1. 6. 4. 2. 2. 6. 3. 3. 1. 5. 6. 4. 5. 2. 4. 1. 3. 5. 5.\n",
      " 2. 2. 5. 3. 2. 3. 5. 6. 4. 2. 3. 4. 2. 6. 1. 3. 4. 4. 6. 5. 2. 3. 4. 1.\n",
      " 5. 1. 6. 6. 1. 6. 4. 3. 5. 3. 2. 1. 1. 1. 1. 2. 3. 6.] [6. 3. 2. 6. 5. 1. 4. 2. 1. 4. 4. 5. 5. 5. 3. 4. 2. 2. 2. 2. 1. 5. 1. 5.\n",
      " 6. 3. 1. 3. 5. 5. 4. 4. 3. 2. 1. 2. 6. 2. 5. 4. 3. 6. 6. 3. 2. 6. 1. 4.\n",
      " 1. 1. 1. 2. 6. 3. 6. 3. 3. 4. 4. 4. 4. 4. 4. 5. 1. 5. 4. 3. 2. 5. 6. 1.\n",
      " 2. 1. 5. 2. 2. 1. 4. 1. 1. 2. 4. 3. 3. 3. 6. 5. 1. 5. 6. 5. 4. 1. 4. 3.\n",
      " 6. 1. 2. 3. 6. 1. 6. 6. 2. 2. 1. 3. 2. 2. 6. 6. 4. 4. 3. 5. 5. 4. 4. 6.\n",
      " 5. 2. 6. 3. 2. 5. 6. 1. 2. 4. 5. 3. 5. 6. 6. 3. 6. 3. 1. 2. 3. 5. 1. 3.\n",
      " 2. 2. 1. 3. 2. 3. 1. 5. 5. 1. 2. 2. 6. 1. 5. 1. 5. 2. 3. 1. 5. 3. 4. 5.\n",
      " 1. 1. 3. 5. 1. 4. 1. 5. 1. 5. 2. 5. 4. 4. 2. 3. 4. 6. 6. 6. 1. 1. 2. 6.\n",
      " 4. 2. 3. 4. 2. 2. 5. 1. 2. 5. 1. 5. 4. 3. 6. 6. 1. 3. 4. 2. 5. 1. 4. 1.\n",
      " 5. 1. 6. 4. 6. 1. 6. 5. 1. 6. 3. 5. 1. 5. 2. 6. 3. 2. 6. 5. 2. 6. 4. 4.\n",
      " 3. 5. 5. 6. 6. 1. 5. 4. 3. 1. 4. 5. 6. 4. 1. 1. 6. 1. 1. 6. 4. 6. 3. 3.\n",
      " 5. 2. 6. 1. 3. 6. 3. 6. 6. 1. 5. 1. 4. 3. 3. 3. 4. 6. 6. 4. 2. 6. 2. 3.\n",
      " 5. 1. 5. 5. 2. 2. 2. 4. 2. 4. 3. 1. 2. 5. 6. 1. 5. 4. 3. 5. 3. 5. 2. 3.\n",
      " 5. 2. 3. 4. 6. 1. 6. 4. 2. 1. 6. 4. 4. 4. 3. 2. 4. 1. 6. 3. 1. 2. 5. 4.\n",
      " 1. 2. 1. 1. 5. 4. 4. 4. 4. 5. 6. 3. 3. 5. 3. 5. 2. 6. 6. 2. 6. 1. 5. 5.\n",
      " 3. 1. 6. 2. 3. 2. 2. 1. 4. 1. 1. 6. 4. 6. 5. 4. 2. 2. 5. 3. 1. 5. 6. 4.\n",
      " 3. 2. 4. 5. 3. 4. 4. 5. 3. 1. 4. 3. 3. 2. 3. 4. 5. 5. 6. 5. 6. 4. 3. 6.\n",
      " 2. 1. 5. 1. 2. 4. 5. 2. 4. 5. 6. 1. 2. 4. 4. 3. 2. 1. 6. 3. 6. 1. 3. 2.\n",
      " 2. 5. 2. 5. 4. 1. 6. 1. 1. 4. 1. 1. 2. 2. 4. 1. 6. 4. 6. 3. 2. 4. 1. 2.\n",
      " 6. 4. 4. 6. 5. 3. 2. 5. 4. 3. 1. 4. 4. 5. 6. 4. 4. 3. 4. 2. 6. 4. 2. 3.\n",
      " 4. 5. 3. 5. 5. 3.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "y_pred = clf.predict(x_val)\n",
    "print(metrics.accuracy_score(y_val, y_pred))\n",
    "print(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3:00 non-compute time\n",
    "5:00 attempted compute before cancel\n",
    "1:15 new compute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How well does it perform on test data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9897119341563786\n",
      "[6. 3. 2. 6. 5. 1. 4. 2. 1. 4. 4. 5. 5. 5. 3. 4. 2. 2. 2. 2. 1. 5. 1. 5.\n",
      " 6. 3. 1. 3. 5. 5. 4. 4. 3. 2. 1. 2. 6. 2. 5. 4. 3. 6. 6. 3. 2. 6. 1. 4.\n",
      " 1. 1. 1. 2. 6. 3. 6. 3. 3. 4. 4. 4. 4. 4. 4. 5. 1. 5. 4. 3. 2. 5. 6. 1.\n",
      " 2. 1. 5. 2. 2. 1. 4. 1. 1. 2. 4. 3. 3. 3. 6. 5. 1. 5. 6. 5. 4. 1. 4. 3.\n",
      " 6. 1. 2. 3. 6. 1. 6. 6. 2. 2. 1. 3. 2. 2. 6. 6. 4. 4. 3. 5. 5. 4. 4. 6.\n",
      " 5. 2. 6. 3. 2. 5. 6. 1. 2. 4. 5. 3. 5. 6. 6. 3. 6. 3. 1. 2. 3. 5. 1. 3.\n",
      " 2. 2. 1. 3. 2. 3. 1. 5. 5. 1. 2. 2. 6. 1. 5. 1. 5. 2. 3. 1. 5. 3. 4. 5.\n",
      " 1. 1. 3. 5. 1. 4. 1. 5. 1. 5. 2. 5. 4. 4. 2. 3. 4. 6. 6. 6. 1. 1. 2. 6.\n",
      " 4. 2. 3. 4. 2. 2. 5. 1. 2. 5. 1. 5. 4. 3. 6. 6. 1. 3. 4. 2. 5. 1. 4. 1.\n",
      " 5. 1. 6. 4. 6. 1. 6. 5. 1. 6. 3. 5. 1. 5. 2. 6. 3. 2. 6. 5. 2. 6. 4. 4.\n",
      " 3. 5. 5. 6. 6. 1. 5. 4. 3. 1. 4. 5. 6. 4. 1. 1. 6. 1. 1. 6. 4. 6. 3. 3.\n",
      " 5. 2. 6. 1. 3. 6. 3. 6. 6. 1. 5. 1. 4. 3. 3. 3. 4. 6. 6. 4. 2. 6. 2. 3.\n",
      " 5. 1. 5. 5. 2. 2. 2. 4. 2. 4. 3. 1. 2. 5. 6. 1. 5. 4. 3. 5. 3. 5. 2. 3.\n",
      " 5. 2. 3. 4. 6. 1. 6. 4. 2. 1. 6. 4. 4. 4. 3. 2. 4. 1. 6. 3. 1. 2. 5. 4.\n",
      " 1. 2. 1. 1. 5. 4. 4. 4. 4. 5. 6. 3. 3. 5. 3. 5. 2. 6. 6. 2. 6. 1. 5. 5.\n",
      " 3. 1. 6. 2. 3. 2. 2. 1. 4. 1. 1. 6. 4. 6. 5. 4. 2. 2. 5. 3. 1. 5. 6. 4.\n",
      " 3. 2. 4. 5. 3. 4. 4. 5. 3. 1. 4. 3. 3. 2. 3. 4. 5. 5. 6. 5. 6. 4. 3. 6.\n",
      " 2. 1. 5. 1. 2. 4. 5. 2. 4. 5. 6. 1. 2. 4. 4. 3. 2. 1. 6. 3. 6. 1. 3. 2.\n",
      " 2. 5. 2. 5. 4. 1. 6. 1. 1. 4. 1. 1. 2. 2. 4. 1. 6. 4. 6. 3. 2. 4. 1. 2.\n",
      " 6. 4. 4. 6. 5. 3. 2. 5. 4. 3. 1. 4. 4. 5. 6. 4. 4. 3. 4. 2. 6. 4. 2. 3.\n",
      " 4. 5. 3. 5. 5. 3.] [6. 3. 2. 6. 5. 1. 4. 2. 1. 4. 4. 5. 5. 5. 3. 4. 2. 2. 2. 2. 1. 5. 1. 5.\n",
      " 6. 3. 1. 3. 5. 5. 4. 4. 3. 2. 1. 2. 6. 2. 5. 4. 3. 6. 6. 3. 2. 6. 1. 4.\n",
      " 1. 1. 1. 2. 6. 3. 6. 3. 3. 4. 4. 4. 4. 5. 4. 5. 1. 5. 4. 3. 2. 4. 6. 1.\n",
      " 2. 1. 5. 2. 2. 1. 4. 1. 1. 2. 4. 3. 3. 3. 6. 5. 1. 5. 6. 5. 4. 1. 4. 3.\n",
      " 6. 1. 2. 3. 6. 1. 6. 6. 2. 2. 1. 3. 2. 2. 6. 6. 4. 4. 3. 5. 5. 4. 4. 6.\n",
      " 5. 2. 6. 3. 2. 5. 6. 1. 2. 5. 5. 3. 5. 6. 6. 3. 6. 3. 1. 2. 3. 5. 1. 3.\n",
      " 2. 2. 1. 3. 2. 3. 1. 5. 5. 1. 2. 2. 6. 1. 5. 1. 5. 2. 3. 1. 5. 3. 4. 5.\n",
      " 1. 1. 3. 5. 1. 4. 1. 5. 1. 5. 2. 4. 4. 4. 2. 3. 4. 6. 6. 6. 1. 1. 2. 6.\n",
      " 4. 2. 3. 4. 2. 2. 5. 1. 2. 5. 1. 5. 4. 3. 6. 6. 1. 3. 4. 2. 5. 1. 4. 1.\n",
      " 5. 1. 6. 4. 6. 1. 6. 5. 1. 6. 3. 5. 1. 5. 2. 6. 3. 2. 6. 5. 2. 6. 4. 4.\n",
      " 3. 5. 5. 6. 6. 1. 5. 4. 3. 1. 4. 5. 6. 4. 1. 1. 6. 1. 1. 6. 4. 6. 3. 3.\n",
      " 5. 2. 6. 1. 3. 6. 3. 6. 6. 1. 5. 1. 4. 3. 3. 3. 4. 6. 6. 4. 2. 6. 2. 3.\n",
      " 5. 1. 5. 5. 2. 2. 2. 4. 2. 4. 3. 1. 2. 5. 6. 1. 5. 4. 3. 5. 3. 5. 2. 3.\n",
      " 5. 2. 3. 4. 6. 1. 6. 4. 2. 1. 6. 4. 4. 4. 3. 2. 4. 1. 6. 3. 1. 2. 5. 4.\n",
      " 1. 2. 1. 1. 5. 4. 4. 4. 4. 5. 6. 3. 3. 5. 3. 5. 2. 6. 6. 2. 6. 1. 5. 5.\n",
      " 3. 1. 6. 2. 3. 2. 2. 1. 4. 1. 1. 6. 4. 6. 5. 4. 2. 2. 5. 3. 1. 5. 6. 4.\n",
      " 3. 2. 4. 5. 3. 4. 4. 5. 3. 1. 4. 3. 3. 2. 3. 4. 5. 5. 6. 5. 6. 4. 3. 6.\n",
      " 2. 1. 5. 1. 2. 4. 5. 2. 4. 5. 6. 1. 2. 4. 4. 3. 2. 1. 6. 3. 6. 1. 3. 2.\n",
      " 2. 5. 2. 5. 4. 1. 6. 1. 1. 4. 1. 1. 2. 2. 4. 1. 6. 4. 6. 3. 2. 4. 1. 2.\n",
      " 6. 5. 4. 6. 5. 3. 2. 5. 4. 3. 1. 4. 4. 5. 6. 4. 4. 3. 4. 2. 6. 4. 2. 3.\n",
      " 4. 5. 3. 5. 5. 3.]\n"
     ]
    }
   ],
   "source": [
    "y_pred_unseen = clf.predict(x_test)\n",
    "print(metrics.accuracy_score(y_test, y_pred_unseen))\n",
    "print(y_test, y_pred_unseen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2:10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          rank  ensemble_weight               type      cost   duration\n",
      "model_id                                                               \n",
      "8            1             0.02        extra_trees  0.004938  11.396656\n",
      "2            2             0.02        extra_trees  0.006173  12.457557\n",
      "6            3             0.02  gradient_boosting  0.018519  17.928695\n",
      "9            4             0.92                sgd  0.021605   9.194768\n",
      "13           5             0.02  gradient_boosting  0.060494  15.043605\n"
     ]
    }
   ],
   "source": [
    "print(clf.leaderboard())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traditional Methods trained on every file, tested on one at a time (untuned)\n",
    "MinMaxScaler is applied to these tests. All models are untuned. The model will be trained on file A, tested on files B,C,D.., then on B, tested on A,C,D.. etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "from time import process_time\n",
    "from os import listdir, chdir, environ, path\n",
    "\n",
    "def warn(*args, **kwargs):\n",
    "  pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    environ[\"PYTHONWARNINGS\"] = \"ignore\"\n",
    "\n",
    "import numpy as np\n",
    "from modules.NetworkTraffic import NT2\n",
    "from sklearn import model_selection, metrics\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from autosklearn.classification import AutoSklearnClassifier\n",
    "\n",
    "FilesToTest = list()\n",
    "chdir(\"../../data/other\")\n",
    "for file in listdir():\n",
    "  if file.endswith(\".csv\"):\n",
    "    if file.startswith('b'):\n",
    "      FilesToTest.append(file)\n",
    "\n",
    "TestSize = [0.4]\n",
    "ModelsToTest = [AutoSklearnClassifer(time_left_for_this_task=30, n_jobs=-1, memory_limit=4096)]\n",
    "OutputResults = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "theseFiles = dict()\n",
    "for file in FilesToTest:\n",
    "  theseFiles[file] = NT2(file, transform=False, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import pandas as pd\n",
    "\n",
    "def testMe():\n",
    "  OutputResults.clear()\n",
    "\n",
    "  for file in theseFiles:\n",
    "    print(file, end=', ')\n",
    "    OutputResults[file] = dict()\n",
    "    currentFileData = theseFiles[file]\n",
    "    restOfFiles = deepcopy(theseFiles)\n",
    "    restOfFiles.pop(file)\n",
    "    print('[', end='')\n",
    "    for model in ModelsToTest:\n",
    "      print(str(model), end=' ')\n",
    "      OutputResults[file][str(model)] = dict()\n",
    "      clf = make_pipeline(MinMaxScaler(), model)\n",
    "      clf.fit(currentFileData.data, currentFileData.target)\n",
    "\n",
    "      for file2 in restOfFiles:\n",
    "        testFileData = theseFiles[file2]\n",
    "        y_pred = clf.predict(testFileData.data)\n",
    "        score = metrics.accuracy_score(testFileData.target, y_pred)\n",
    "        OutputResults[file][str(model)].update({file2: {\"Accuracy\":score}})\n",
    "        try:\n",
    "          OutputResults[file][str(model)][\"Final Ensemble\"] = str(model.show_models())\n",
    "        except:\n",
    "          pass\n",
    "        try:\n",
    "          if df_leader.empty: df_leader = model.leaderboard()\n",
    "          else: df_leader = pd.concat([df_leader, model.leaderboard()], ignore_index=False)\n",
    "        except: pass\n",
    "        try:\n",
    "          OutputResults[file][str(model)][\"Sprint\"] = str(model.sprint_statistics())\n",
    "        except KeyError:\n",
    "          pass\n",
    "    print(']')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def writeMe():\n",
    "  with open(\"EveryFileTransfer_Untuned_AllTestResults.json\", \"a\") as f:\n",
    "    f.write(json.dumps(OutputResults, indent=2))\n",
    "\n",
    "  with open(\"EveryFileTransfer_Untuned_ModelResults.csv\", \"a\") as f3:\n",
    "    if not path.exists(\"EveryFileTransfer_Untuned_ModelResults.csv\"): f3.write(\"Trained On,Tested On,Model,Accuracy\\n\")\n",
    "    for file in OutputResults:\n",
    "      for file2 in OutputResults[file]:\n",
    "        for model in OutputResults[file][file2]:\n",
    "          f3.write(f\"{file},{model},{file2},{OutputResults[file][file2][model]['Accuracy']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b1000d35.csv, [RandomForestClassifier() GradientBoostingClassifier() DecisionTreeClassifier() MLPClassifier() LinearSVC() ]\n",
      "b1000d60.csv, [RandomForestClassifier() GradientBoostingClassifier() DecisionTreeClassifier() MLPClassifier() LinearSVC() ]\n",
      "b1000d35.csv, [RandomForestClassifier() GradientBoostingClassifier() DecisionTreeClassifier() MLPClassifier() LinearSVC() ]\n",
      "b1000d60.csv, [RandomForestClassifier() GradientBoostingClassifier() DecisionTreeClassifier() MLPClassifier() LinearSVC() ]\n",
      "b1000d35.csv, [RandomForestClassifier() GradientBoostingClassifier() DecisionTreeClassifier() MLPClassifier() LinearSVC() ]\n",
      "b1000d60.csv, [RandomForestClassifier() GradientBoostingClassifier() DecisionTreeClassifier() MLPClassifier() LinearSVC() ]\n",
      "b1000d35.csv, [RandomForestClassifier() GradientBoostingClassifier() DecisionTreeClassifier() MLPClassifier() LinearSVC() ]\n",
      "b1000d60.csv, [RandomForestClassifier() GradientBoostingClassifier() DecisionTreeClassifier() MLPClassifier() LinearSVC() ]\n",
      "b1000d35.csv, [RandomForestClassifier() GradientBoostingClassifier() DecisionTreeClassifier() MLPClassifier() LinearSVC() ]\n",
      "b1000d60.csv, [RandomForestClassifier() GradientBoostingClassifier() DecisionTreeClassifier() MLPClassifier() LinearSVC() ]\n"
     ]
    }
   ],
   "source": [
    "REPEATS = 3\n",
    "for _ in range(0, REPEATS):\n",
    "  testMe()\n",
    "  writeMe()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

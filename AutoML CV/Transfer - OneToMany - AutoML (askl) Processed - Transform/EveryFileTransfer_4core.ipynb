{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoML (askl) trained on every file individually, tested on the rest (4 cores, 30 seconds per file)\n",
    "AutoML's data preprocessing is applied to these tests. The model will be trained on file A, tested on files B,C,D.., then on B, tested on A,C,D.. etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "from time import process_time\n",
    "from os import listdir, chdir, environ\n",
    "\n",
    "def warn(*args, **kwargs):\n",
    "  pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    environ[\"PYTHONWARNINGS\"] = \"ignore\"\n",
    "\n",
    "from modules.NetworkTraffic import NT2\n",
    "from sklearn import model_selection, metrics\n",
    "from autosklearn.classification import AutoSklearnClassifier\n",
    "\n",
    "FilesToTest = list()\n",
    "chdir(\"../../data\")\n",
    "for file in listdir():\n",
    "  if file.endswith(\".csv\"):\n",
    "    FilesToTest.append(file)\n",
    "\n",
    "TestSize = [0.4]\n",
    "ModelsToTest = [AutoSklearnClassifier(time_left_for_this_task=30, memory_limit=4096, n_jobs=-1)]\n",
    "OutputResults = dict()\n",
    "#ModelResults = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "df_leader = None\n",
    "\n",
    "def testMe():\n",
    "  global df_leader\n",
    "  df_leader = pd.DataFrame()\n",
    "  OutputResults.clear()\n",
    "  #ModelResults.clear()\n",
    "\n",
    "  for index, file in enumerate(FilesToTest):\n",
    "    print(file, end=', ')\n",
    "    OutputResults[file] = dict()\n",
    "    currentFileData = NT2(file, transform=True, drop=True)\n",
    "    restOfFiles = deepcopy(FilesToTest)\n",
    "    restOfFiles.pop(index)\n",
    "    restOfTheFilesData = NT2(restOfFiles, transform=True, drop=True)\n",
    "\n",
    "    for model in ModelsToTest:\n",
    "      print(f\"{file} : {str(model)}\", end=\", \")\n",
    "      model.fit(currentFileData.data, currentFileData.target)\n",
    "      y_pred = model.predict(restOfTheFilesData.data)\n",
    "      score = metrics.accuracy_score(restOfTheFilesData.target, y_pred)\n",
    "      OutputResults[file].update({str(model): {\"Accuracy\": score}})\n",
    "      try:\n",
    "        OutputResults[file][str(model)][\"Final Ensemble\"] = str(model.show_models())\n",
    "      except:\n",
    "        pass\n",
    "      try:\n",
    "        if df_leader.empty: df_leader = model.leaderboard()\n",
    "        else: df_leader = pd.concat([df_leader, model.leaderboard()], ignore_index=False)\n",
    "      except: pass\n",
    "      try:\n",
    "        OutputResults[file][str(model)][\"Sprint\"] = str(model.sprint_statistics())\n",
    "      except KeyError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from os import path\n",
    "\n",
    "def writeMe():\n",
    "  with open(\"EveryFileTransfer_Untuned_AllTestResults.json\", \"a\") as f:\n",
    "    f.write(json.dumps(OutputResults, indent=2))\n",
    "\n",
    "  df_leader.to_csv(\"Leaderboard.csv\", mode='a')\n",
    "\n",
    "  with open(\"EveryFileTransfer_Untuned_ModelResults.csv\", \"a\") as f3:\n",
    "    if path.exists(\"EveryFileTransfer_Untuned_ModelResults.csv\"): f3.write(\"File Trained On,Model,Accuracy,Runtime\\n\")\n",
    "    for file in OutputResults:\n",
    "      for model in OutputResults[file]:\n",
    "        f3.write(f\"{file},{model},{OutputResults[file][model]['Accuracy']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------0------\n",
      "b5000d100.csv, b5000d100.csv : AutoSklearnClassifier(memory_limit=4096, n_jobs=-1, time_left_for_this_task=30), b5000d30.csv, b5000d30.csv : AutoSklearnClassifier(memory_limit=4096, n_jobs=-1, per_run_time_limit=12,\n",
      "                      time_left_for_this_task=30), b100d10.csv, b100d10.csv : AutoSklearnClassifier(memory_limit=4096, n_jobs=-1, per_run_time_limit=12,\n",
      "                      time_left_for_this_task=30), b1000d10.csv, b1000d10.csv : AutoSklearnClassifier(memory_limit=4096, n_jobs=-1, per_run_time_limit=12,\n",
      "                      time_left_for_this_task=30), b1000d100.csv, b1000d100.csv : AutoSklearnClassifier(memory_limit=4096, n_jobs=-1, per_run_time_limit=12,\n",
      "                      time_left_for_this_task=30), b100d100.csv, b100d100.csv : AutoSklearnClassifier(memory_limit=4096, n_jobs=-1, per_run_time_limit=12,\n",
      "                      time_left_for_this_task=30), b5000d10.csv, b5000d10.csv : AutoSklearnClassifier(memory_limit=4096, n_jobs=-1, per_run_time_limit=12,\n",
      "                      time_left_for_this_task=30), b1000d30.csv, b1000d30.csv : AutoSklearnClassifier(memory_limit=4096, n_jobs=-1, per_run_time_limit=12,\n",
      "                      time_left_for_this_task=30), b100d30.csv, b100d30.csv : AutoSklearnClassifier(memory_limit=4096, n_jobs=-1, per_run_time_limit=12,\n",
      "                      time_left_for_this_task=30), \n",
      "------1------\n",
      "b5000d100.csv, b5000d100.csv : AutoSklearnClassifier(memory_limit=4096, n_jobs=-1, per_run_time_limit=12,\n",
      "                      time_left_for_this_task=30), b5000d30.csv, b5000d30.csv : AutoSklearnClassifier(memory_limit=4096, n_jobs=-1, per_run_time_limit=12,\n",
      "                      time_left_for_this_task=30), b100d10.csv, b100d10.csv : AutoSklearnClassifier(memory_limit=4096, n_jobs=-1, per_run_time_limit=12,\n",
      "                      time_left_for_this_task=30), b1000d10.csv, b1000d10.csv : AutoSklearnClassifier(memory_limit=4096, n_jobs=-1, per_run_time_limit=12,\n",
      "                      time_left_for_this_task=30), b1000d100.csv, b1000d100.csv : AutoSklearnClassifier(memory_limit=4096, n_jobs=-1, per_run_time_limit=12,\n",
      "                      time_left_for_this_task=30), b100d100.csv, b100d100.csv : AutoSklearnClassifier(memory_limit=4096, n_jobs=-1, per_run_time_limit=12,\n",
      "                      time_left_for_this_task=30), b5000d10.csv, b5000d10.csv : AutoSklearnClassifier(memory_limit=4096, n_jobs=-1, per_run_time_limit=12,\n",
      "                      time_left_for_this_task=30), b1000d30.csv, b1000d30.csv : AutoSklearnClassifier(memory_limit=4096, n_jobs=-1, per_run_time_limit=12,\n",
      "                      time_left_for_this_task=30), b100d30.csv, b100d30.csv : AutoSklearnClassifier(memory_limit=4096, n_jobs=-1, per_run_time_limit=12,\n",
      "                      time_left_for_this_task=30), "
     ]
    }
   ],
   "source": [
    "REPEATS = 2\n",
    "for _ in range(0, REPEATS):\n",
    "  print(f\"\\n------{_}------\")\n",
    "  testMe()\n",
    "  writeMe()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

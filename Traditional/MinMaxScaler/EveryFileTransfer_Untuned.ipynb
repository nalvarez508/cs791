{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traditional Methods trained on every file, tuned on the rest (untuned)\n",
    "MinMaxScaler is applied to these tests. All models are untuned. The model will be trained on file A, tested on files B,C,D.., then on B, tested on A,C,D.. etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "from time import process_time\n",
    "from os import listdir, chdir\n",
    "\n",
    "def warn(*args, **kwargs):\n",
    "  pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "\n",
    "from modules.NetworkTraffic import NetworkTraffic\n",
    "from sklearn import model_selection, metrics\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "FilesToTest = list()\n",
    "chdir(\"../../data\")\n",
    "for file in listdir():\n",
    "  if file.endswith(\".csv\"):\n",
    "    FilesToTest.append(file)\n",
    "\n",
    "TestSize = [0.4]\n",
    "ModelsToTest = [RandomForestClassifier(), GradientBoostingClassifier(), DecisionTreeClassifier(), MLPClassifier(), LinearSVC()]\n",
    "OutputResults = dict()\n",
    "#ModelResults = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testModel(model, x_train, x_test, y_train, y_test):\n",
    "  print(f\"Testing {str(model)}\", end=', ')\n",
    "  start = process_time()\n",
    "\n",
    "  ### Begin timing\n",
    "  temp_clf = model\n",
    "  temp_clf.fit(x_train, y_train)\n",
    "\n",
    "  y_pred = temp_clf.predict(x_test)\n",
    "  ### End timing\n",
    "\n",
    "  stop = process_time()\n",
    "\n",
    "  # Results\n",
    "  tempDict = {\n",
    "    \"Accuracy\": metrics.accuracy_score(y_test, y_pred),\n",
    "    \"Balanced Accuracy\": metrics.balanced_accuracy_score(y_test, y_pred),\n",
    "    \"F1 Micro\": metrics.f1_score(y_test, y_pred, average='micro'),\n",
    "    \"Precision Micro\": metrics.f1_score(y_test, y_pred, average='micro'),\n",
    "    \"Recall Micro\": metrics.recall_score(y_test, y_pred, average='micro'),\n",
    "    \"Runtime\": stop-start,\n",
    "  }\n",
    "  return tempDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateModelResults(size, model, results):\n",
    "  def changeKeyValue():\n",
    "    try:\n",
    "      ModelResults[size][model][key] += results[key]\n",
    "    except KeyError:\n",
    "      ModelResults[size][model][key] = results[key]\n",
    "  \n",
    "  # For each metric, attempt to set or add to the value\n",
    "  for key in results:\n",
    "    try:\n",
    "      changeKeyValue()\n",
    "    except KeyError:\n",
    "      ModelResults[size][model] = dict()\n",
    "      changeKeyValue()\n",
    "\n",
    "# Divide each metric by the total number of files tested\n",
    "def findAveragesForModelResults(fileCount):\n",
    "  for size in ModelResults:\n",
    "    for model in ModelResults[size]:\n",
    "      for metric in ModelResults[size][model]:\n",
    "        ModelResults[size][model][metric] /= fileCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Searching with test size of 40.0%...\n",
      "b5000d100.csv, [[2.1940e+03 8.0000e+00 1.0000e+02 ... 1.8000e+00 1.4480e+04 6.4088e+04]\n",
      " [1.5380e+03 1.1000e+01 1.0000e+02 ... 2.2000e+00 1.4480e+04 6.4088e+04]\n",
      " [1.4180e+03 1.0000e+01 1.0000e+02 ... 1.3000e+00 1.4480e+04 6.4088e+04]\n",
      " ...\n",
      " [1.3050e+04 0.0000e+00 4.1692e+01 ... 4.7800e+01 1.4480e+04 6.4088e+04]\n",
      " [1.2278e+04 1.0000e+00 5.7334e+01 ... 3.8900e+01 1.4480e+04 6.4088e+04]\n",
      " [1.3812e+04 0.0000e+00 4.4600e+01 ... 5.5600e+01 1.4480e+04 6.4088e+04]]\n",
      "[4 4 4 ... 6 6 6]\n",
      "[[4.9580e+03 2.8000e+01 3.0000e+01 ... 5.0000e+00 1.4480e+04 6.4088e+04]\n",
      " [5.7570e+03 2.7000e+01 3.0000e+01 ... 5.3000e+00 1.4480e+04 6.4088e+04]\n",
      " [4.5050e+03 3.1000e+01 3.0000e+01 ... 7.3000e+00 1.4480e+04 6.4088e+04]\n",
      " ...\n",
      " [6.6897e+04 0.0000e+00 1.8973e+01 ... 9.6100e+01 1.4480e+04 6.4088e+04]\n",
      " [6.6001e+04 0.0000e+00 1.2819e+01 ... 9.6100e+01 1.4480e+04 6.4088e+04]\n",
      " [6.5989e+04 0.0000e+00 1.6517e+01 ... 9.6100e+01 1.4480e+04 6.4088e+04]]\n",
      "[4 4 4 ... 6 6 6]\n",
      "Testing RandomForestClassifier(), "
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: 'continuous-multioutput'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/nick/Documents/cs791/Traditional/MinMaxScaler/EveryFileTransfer_Untuned.ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/nick/Documents/cs791/Traditional/MinMaxScaler/EveryFileTransfer_Untuned.ipynb#ch0000004?line=17'>18</a>\u001b[0m x_train, x_test, y_train, y_test \u001b[39m=\u001b[39m currentFileData\u001b[39m.\u001b[39mdata, currentFileData\u001b[39m.\u001b[39mtarget, restOfTheFilesData\u001b[39m.\u001b[39mdata, restOfTheFilesData\u001b[39m.\u001b[39mtarget\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/nick/Documents/cs791/Traditional/MinMaxScaler/EveryFileTransfer_Untuned.ipynb#ch0000004?line=19'>20</a>\u001b[0m \u001b[39mfor\u001b[39;00m model \u001b[39min\u001b[39;00m ModelsToTest:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/nick/Documents/cs791/Traditional/MinMaxScaler/EveryFileTransfer_Untuned.ipynb#ch0000004?line=20'>21</a>\u001b[0m   \u001b[39m#print(f\"{file} : {str(model)}...\")\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/nick/Documents/cs791/Traditional/MinMaxScaler/EveryFileTransfer_Untuned.ipynb#ch0000004?line=21'>22</a>\u001b[0m   results \u001b[39m=\u001b[39m testModel(model, x_train, x_test, y_train, y_test)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/nick/Documents/cs791/Traditional/MinMaxScaler/EveryFileTransfer_Untuned.ipynb#ch0000004?line=22'>23</a>\u001b[0m   OutputResults[size][file]\u001b[39m.\u001b[39mupdate({\u001b[39mstr\u001b[39m(model): results})\n",
      "\u001b[1;32m/home/nick/Documents/cs791/Traditional/MinMaxScaler/EveryFileTransfer_Untuned.ipynb Cell 3'\u001b[0m in \u001b[0;36mtestModel\u001b[0;34m(model, x_train, x_test, y_train, y_test)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/nick/Documents/cs791/Traditional/MinMaxScaler/EveryFileTransfer_Untuned.ipynb#ch0000002?line=4'>5</a>\u001b[0m \u001b[39m### Begin timing\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/nick/Documents/cs791/Traditional/MinMaxScaler/EveryFileTransfer_Untuned.ipynb#ch0000002?line=5'>6</a>\u001b[0m temp_clf \u001b[39m=\u001b[39m model\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/nick/Documents/cs791/Traditional/MinMaxScaler/EveryFileTransfer_Untuned.ipynb#ch0000002?line=6'>7</a>\u001b[0m temp_clf\u001b[39m.\u001b[39;49mfit(x_train, y_train)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/nick/Documents/cs791/Traditional/MinMaxScaler/EveryFileTransfer_Untuned.ipynb#ch0000002?line=8'>9</a>\u001b[0m y_pred \u001b[39m=\u001b[39m temp_clf\u001b[39m.\u001b[39mpredict(x_test)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/nick/Documents/cs791/Traditional/MinMaxScaler/EveryFileTransfer_Untuned.ipynb#ch0000002?line=9'>10</a>\u001b[0m \u001b[39m### End timing\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:331\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    <a href='file:///home/nick/.local/lib/python3.8/site-packages/sklearn/ensemble/_forest.py?line=326'>327</a>\u001b[0m     y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mreshape(y, (\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m))\n\u001b[1;32m    <a href='file:///home/nick/.local/lib/python3.8/site-packages/sklearn/ensemble/_forest.py?line=328'>329</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n\u001b[0;32m--> <a href='file:///home/nick/.local/lib/python3.8/site-packages/sklearn/ensemble/_forest.py?line=330'>331</a>\u001b[0m y, expanded_class_weight \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_y_class_weight(y)\n\u001b[1;32m    <a href='file:///home/nick/.local/lib/python3.8/site-packages/sklearn/ensemble/_forest.py?line=332'>333</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(y, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m!=\u001b[39m DOUBLE \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m y\u001b[39m.\u001b[39mflags\u001b[39m.\u001b[39mcontiguous:\n\u001b[1;32m    <a href='file:///home/nick/.local/lib/python3.8/site-packages/sklearn/ensemble/_forest.py?line=333'>334</a>\u001b[0m     y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mascontiguousarray(y, dtype\u001b[39m=\u001b[39mDOUBLE)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:559\u001b[0m, in \u001b[0;36mForestClassifier._validate_y_class_weight\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    <a href='file:///home/nick/.local/lib/python3.8/site-packages/sklearn/ensemble/_forest.py?line=557'>558</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_validate_y_class_weight\u001b[39m(\u001b[39mself\u001b[39m, y):\n\u001b[0;32m--> <a href='file:///home/nick/.local/lib/python3.8/site-packages/sklearn/ensemble/_forest.py?line=558'>559</a>\u001b[0m     check_classification_targets(y)\n\u001b[1;32m    <a href='file:///home/nick/.local/lib/python3.8/site-packages/sklearn/ensemble/_forest.py?line=560'>561</a>\u001b[0m     y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mcopy(y)\n\u001b[1;32m    <a href='file:///home/nick/.local/lib/python3.8/site-packages/sklearn/ensemble/_forest.py?line=561'>562</a>\u001b[0m     expanded_class_weight \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/multiclass.py:183\u001b[0m, in \u001b[0;36mcheck_classification_targets\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    <a href='file:///home/nick/.local/lib/python3.8/site-packages/sklearn/utils/multiclass.py?line=179'>180</a>\u001b[0m y_type \u001b[39m=\u001b[39m type_of_target(y)\n\u001b[1;32m    <a href='file:///home/nick/.local/lib/python3.8/site-packages/sklearn/utils/multiclass.py?line=180'>181</a>\u001b[0m \u001b[39mif\u001b[39;00m y_type \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m [\u001b[39m'\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mmulticlass-multioutput\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m    <a href='file:///home/nick/.local/lib/python3.8/site-packages/sklearn/utils/multiclass.py?line=181'>182</a>\u001b[0m                   \u001b[39m'\u001b[39m\u001b[39mmultilabel-indicator\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mmultilabel-sequences\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[0;32m--> <a href='file:///home/nick/.local/lib/python3.8/site-packages/sklearn/utils/multiclass.py?line=182'>183</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mUnknown label type: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m y_type)\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown label type: 'continuous-multioutput'"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "OutputResults.clear()\n",
    "#ModelResults.clear()\n",
    "\n",
    "for size in TestSize:\n",
    "  print(f\"\\nSearching with test size of {size*100}%...\")\n",
    "  OutputResults[size] = dict()\n",
    "  #ModelResults[size] = dict()\n",
    "\n",
    "  for index, file in enumerate(FilesToTest):\n",
    "    print(file, end=', ')\n",
    "    OutputResults[size][file] = dict()\n",
    "    currentFileData = NetworkTraffic(file, testSize=size, doNorm=True, doNormAll=True)\n",
    "    restOfFiles = deepcopy(FilesToTest)\n",
    "    restOfFiles.pop(index)\n",
    "    restOfTheFilesData = NetworkTraffic(restOfFiles, testSize=size, doNorm=True, doNormAll=True)\n",
    "    x_train, x_test, y_train, y_test = currentFileData.data, currentFileData.target, restOfTheFilesData.data, restOfTheFilesData.target\n",
    "\n",
    "    for model in ModelsToTest:\n",
    "      #print(f\"{file} : {str(model)}...\")\n",
    "      results = testModel(model, x_train, x_test, y_train, y_test)\n",
    "      OutputResults[size][file].update({str(model): results})\n",
    "      #updateModelResults(size, str(model), results)\n",
    "\n",
    "#findAveragesForModelResults(len(FilesToTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"EveryFileTransfer_Untuned_AllTestResults.json\", \"w\") as f:\n",
    "  f.write(json.dumps(OutputResults, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"EveryFileTransfer_Untuned_ModelResults.csv\", \"w\") as f3:\n",
    "  f3.write(\"File Trained On,Model,Accuracy,Runtime\\n\")\n",
    "  for size in OutputResults:\n",
    "    for file in OutputResults[file]:\n",
    "      for model in OutputResults[size][file]:\n",
    "        f3.write(f\"{file},{model},{OutputResults[size][file][model]['Accuracy']},{OutputResults[size][file][model]['Runtime']}\\n\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoML tested on every file individually (4 cores, 60 seconds per file)\n",
    "AutoML's data preprocessing is applied to these tests. Results from each model's tests are compiled into a single average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "from time import process_time\n",
    "from os import listdir, chdir\n",
    "\n",
    "def warn(*args, **kwargs):\n",
    "  pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "\n",
    "from modules.NetworkTraffic import NetworkTraffic\n",
    "from sklearn import model_selection, metrics\n",
    "from autosklearn.experimental.askl2 import AutoSklearn2Classifier\n",
    "\n",
    "FilesToTest = list()\n",
    "chdir(\"../../data\")\n",
    "for file in listdir():\n",
    "  if file.endswith(\".csv\"):\n",
    "    FilesToTest.append(file)\n",
    "\n",
    "TestSize = [0.6]\n",
    "ModelsToTest = [AutoSklearn2Classifier(time_left_for_this_task=30, memory_limit=4096, n_jobs=-1)]\n",
    "OutputResults = dict()\n",
    "ModelResults = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testModel(model, x_train, x_test, y_train, y_test):\n",
    "  start = process_time()\n",
    "\n",
    "  ### Begin timing\n",
    "  temp_clf = model\n",
    "  temp_clf.fit(x_train, y_train)\n",
    "\n",
    "  y_pred = temp_clf.predict(x_test)\n",
    "  ### End timing\n",
    "\n",
    "  stop = process_time()\n",
    "\n",
    "  # Results\n",
    "  tempDict = {\n",
    "    \"Accuracy\": metrics.accuracy_score(y_test, y_pred),\n",
    "    \"Balanced Accuracy\": metrics.balanced_accuracy_score(y_test, y_pred),\n",
    "    \"F1 Micro\": metrics.f1_score(y_test, y_pred, average='micro'),\n",
    "    \"Precision Micro\": metrics.f1_score(y_test, y_pred, average='micro'),\n",
    "    \"Recall Micro\": metrics.recall_score(y_test, y_pred, average='micro'),\n",
    "    \"Runtime\": stop-start,\n",
    "  }\n",
    "  # try:\n",
    "  #   tempDict[\"Leaderboard\"] = str(temp_clf.leaderboard())\n",
    "  # except KeyError:\n",
    "  #   tempDict[\"Leaderboard\"] = None\n",
    "  try:\n",
    "    tempDict[\"Final Ensemble\"] = temp_clf.show_models()\n",
    "  except KeyError:\n",
    "    tempDict[\"Final Ensemble\"] = None\n",
    "  return tempDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateModelResults(size, model, results):\n",
    "  def changeKeyValue():\n",
    "    try:\n",
    "      ModelResults[size][model][key] += results[key]\n",
    "    except KeyError:\n",
    "      ModelResults[size][model][key] = results[key]\n",
    "  \n",
    "  # For each metric, attempt to set or add to the value\n",
    "  for key in results:\n",
    "    if key not in [\"Leaderboard\", \"Final Ensemble\"]:\n",
    "      try:\n",
    "        changeKeyValue()\n",
    "      except KeyError:\n",
    "        ModelResults[size][model] = dict()\n",
    "        changeKeyValue()\n",
    "\n",
    "# Divide each metric by the total number of files tested\n",
    "def findAveragesForModelResults(fileCount):\n",
    "  for size in ModelResults:\n",
    "    for model in ModelResults[size]:\n",
    "      for metric in ModelResults[size][model]:\n",
    "        if metric not in [\"Leaderboard\", \"Final Ensemble\"]:\n",
    "          ModelResults[size][model][metric] /= fileCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Searching with test size of 60.0%...\n",
      "b5000d100.csv : AutoSklearn2Classifier(memory_limit=4096, n_jobs=-1, time_left_for_this_task=30), b5000d30.csv : AutoSklearn2Classifier(memory_limit=4096, metric=accuracy, n_jobs=-1,\n",
      "                       per_run_time_limit=12, time_left_for_this_task=30), b100d10.csv : AutoSklearn2Classifier(memory_limit=4096, metric=accuracy, n_jobs=-1,\n",
      "                       per_run_time_limit=12, time_left_for_this_task=30), "
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Some errors were detected !\n    Line #2 (got 5 columns instead of 25)\n    Line #3 (got 4 columns instead of 25)\n    Line #4 (got 5 columns instead of 25)\n    Line #5 (got 4 columns instead of 25)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/nick/Documents/cs791/AutoML/AutoML Processed/EveryFileIndividually_4core.ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/nick/Documents/cs791/AutoML/AutoML%20Processed/EveryFileIndividually_4core.ipynb#ch0000004?line=8'>9</a>\u001b[0m \u001b[39mfor\u001b[39;00m file \u001b[39min\u001b[39;00m FilesToTest:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/nick/Documents/cs791/AutoML/AutoML%20Processed/EveryFileIndividually_4core.ipynb#ch0000004?line=9'>10</a>\u001b[0m   OutputResults[size][file] \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/nick/Documents/cs791/AutoML/AutoML%20Processed/EveryFileIndividually_4core.ipynb#ch0000004?line=10'>11</a>\u001b[0m   currentFileData \u001b[39m=\u001b[39m NetworkTraffic(file)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/nick/Documents/cs791/AutoML/AutoML%20Processed/EveryFileIndividually_4core.ipynb#ch0000004?line=11'>12</a>\u001b[0m   x_train, x_test, y_train, y_test \u001b[39m=\u001b[39m model_selection\u001b[39m.\u001b[39mtrain_test_split(currentFileData\u001b[39m.\u001b[39mdata, currentFileData\u001b[39m.\u001b[39mtarget)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/nick/Documents/cs791/AutoML/AutoML%20Processed/EveryFileIndividually_4core.ipynb#ch0000004?line=13'>14</a>\u001b[0m   \u001b[39mfor\u001b[39;00m model \u001b[39min\u001b[39;00m ModelsToTest:\n",
      "File \u001b[0;32m~/Documents/cs791/AutoML/AutoML Processed/../../modules/NetworkTraffic.py:15\u001b[0m, in \u001b[0;36mNetworkTraffic.__init__\u001b[0;34m(self, filename, testSize, doNorm, doNormAll)\u001b[0m\n\u001b[1;32m     <a href='file:///home/nick/Documents/cs791/AutoML/AutoML%20Processed/../../modules/NetworkTraffic.py?line=12'>13</a>\u001b[0m \u001b[39m# Import specific file\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/nick/Documents/cs791/AutoML/AutoML%20Processed/../../modules/NetworkTraffic.py?line=13'>14</a>\u001b[0m \u001b[39mif\u001b[39;00m filename \u001b[39m!=\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> <a href='file:///home/nick/Documents/cs791/AutoML/AutoML%20Processed/../../modules/NetworkTraffic.py?line=14'>15</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mall_data \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mgenfromtxt(filename, dtype\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, delimiter\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m,\u001b[39;49m\u001b[39m\"\u001b[39;49m, names\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, excludelist\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39mtransfer_id_\u001b[39;49m\u001b[39m\"\u001b[39;49m], autostrip\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, usecols\u001b[39m=\u001b[39;49m\u001b[39mrange\u001b[39;49m(\u001b[39m1\u001b[39;49m,\u001b[39m26\u001b[39;49m))\n\u001b[1;32m     <a href='file:///home/nick/Documents/cs791/AutoML/AutoML%20Processed/../../modules/NetworkTraffic.py?line=16'>17</a>\u001b[0m \u001b[39m# Import all files as single array \u001b[39;00m\n\u001b[1;32m     <a href='file:///home/nick/Documents/cs791/AutoML/AutoML%20Processed/../../modules/NetworkTraffic.py?line=17'>18</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='file:///home/nick/Documents/cs791/AutoML/AutoML%20Processed/../../modules/NetworkTraffic.py?line=18'>19</a>\u001b[0m   \u001b[39mfrom\u001b[39;00m \u001b[39mos\u001b[39;00m \u001b[39mimport\u001b[39;00m listdir, chdir\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/lib/npyio.py:2145\u001b[0m, in \u001b[0;36mgenfromtxt\u001b[0;34m(fname, dtype, comments, delimiter, skip_header, skip_footer, converters, missing_values, filling_values, usecols, names, excludelist, deletechars, replace_space, autostrip, case_sensitive, defaultfmt, unpack, usemask, loose, invalid_raise, max_rows, encoding, like)\u001b[0m\n\u001b[1;32m   <a href='file:///home/nick/.local/lib/python3.8/site-packages/numpy/lib/npyio.py?line=2142'>2143</a>\u001b[0m \u001b[39m# Raise an exception ?\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/nick/.local/lib/python3.8/site-packages/numpy/lib/npyio.py?line=2143'>2144</a>\u001b[0m \u001b[39mif\u001b[39;00m invalid_raise:\n\u001b[0;32m-> <a href='file:///home/nick/.local/lib/python3.8/site-packages/numpy/lib/npyio.py?line=2144'>2145</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(errmsg)\n\u001b[1;32m   <a href='file:///home/nick/.local/lib/python3.8/site-packages/numpy/lib/npyio.py?line=2145'>2146</a>\u001b[0m \u001b[39m# Issue a warning ?\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/nick/.local/lib/python3.8/site-packages/numpy/lib/npyio.py?line=2146'>2147</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   <a href='file:///home/nick/.local/lib/python3.8/site-packages/numpy/lib/npyio.py?line=2147'>2148</a>\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(errmsg, ConversionWarning, stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Some errors were detected !\n    Line #2 (got 5 columns instead of 25)\n    Line #3 (got 4 columns instead of 25)\n    Line #4 (got 5 columns instead of 25)\n    Line #5 (got 4 columns instead of 25)"
     ]
    }
   ],
   "source": [
    "OutputResults.clear()\n",
    "ModelResults.clear()\n",
    "\n",
    "for size in TestSize:\n",
    "  print(f\"\\nSearching with test size of {size*100}%...\")\n",
    "  OutputResults[size] = dict()\n",
    "  ModelResults[size] = dict()\n",
    "\n",
    "  for file in FilesToTest:\n",
    "    OutputResults[size][file] = dict()\n",
    "    currentFileData = NetworkTraffic(file)\n",
    "    x_train, x_test, y_train, y_test = model_selection.train_test_split(currentFileData.data, currentFileData.target)\n",
    "\n",
    "    for model in ModelsToTest:\n",
    "      print(f\"{file} : {str(model)}\", end=\", \")\n",
    "      results = testModel(model, x_train, x_test, y_train, y_test)\n",
    "      OutputResults[size][file].update({str(model): results})\n",
    "      updateModelResults(size, str(model), results)\n",
    "\n",
    "findAveragesForModelResults(len(FilesToTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object of type int64 is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/nick/Documents/cs791/AutoML/AutoML Processed/EveryFileIndividually_4core.ipynb Cell 6'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/nick/Documents/cs791/AutoML/AutoML%20Processed/EveryFileIndividually_4core.ipynb#ch0000005?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mjson\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/nick/Documents/cs791/AutoML/AutoML%20Processed/EveryFileIndividually_4core.ipynb#ch0000005?line=1'>2</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mEveryFileIndividually_Untuned_AllTestResults.json\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39ma\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/nick/Documents/cs791/AutoML/AutoML%20Processed/EveryFileIndividually_4core.ipynb#ch0000005?line=2'>3</a>\u001b[0m   f\u001b[39m.\u001b[39mwrite(json\u001b[39m.\u001b[39mdumps(OutputResults, indent\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m))\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/nick/Documents/cs791/AutoML/AutoML%20Processed/EveryFileIndividually_4core.ipynb#ch0000005?line=3'>4</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mEveryFileIndividually_Untuned_ModelResults.json\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39ma\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m f2:\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/nick/Documents/cs791/AutoML/AutoML%20Processed/EveryFileIndividually_4core.ipynb#ch0000005?line=4'>5</a>\u001b[0m   f2\u001b[39m.\u001b[39mwrite(json\u001b[39m.\u001b[39mdumps(ModelResults, indent\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m))\n",
      "File \u001b[0;32m/usr/lib/python3.8/json/__init__.py:234\u001b[0m, in \u001b[0;36mdumps\u001b[0;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/lib/python3.8/json/__init__.py?line=231'>232</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///usr/lib/python3.8/json/__init__.py?line=232'>233</a>\u001b[0m     \u001b[39mcls\u001b[39m \u001b[39m=\u001b[39m JSONEncoder\n\u001b[0;32m--> <a href='file:///usr/lib/python3.8/json/__init__.py?line=233'>234</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m(\n\u001b[1;32m    <a href='file:///usr/lib/python3.8/json/__init__.py?line=234'>235</a>\u001b[0m     skipkeys\u001b[39m=\u001b[39;49mskipkeys, ensure_ascii\u001b[39m=\u001b[39;49mensure_ascii,\n\u001b[1;32m    <a href='file:///usr/lib/python3.8/json/__init__.py?line=235'>236</a>\u001b[0m     check_circular\u001b[39m=\u001b[39;49mcheck_circular, allow_nan\u001b[39m=\u001b[39;49mallow_nan, indent\u001b[39m=\u001b[39;49mindent,\n\u001b[1;32m    <a href='file:///usr/lib/python3.8/json/__init__.py?line=236'>237</a>\u001b[0m     separators\u001b[39m=\u001b[39;49mseparators, default\u001b[39m=\u001b[39;49mdefault, sort_keys\u001b[39m=\u001b[39;49msort_keys,\n\u001b[1;32m    <a href='file:///usr/lib/python3.8/json/__init__.py?line=237'>238</a>\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\u001b[39m.\u001b[39;49mencode(obj)\n",
      "File \u001b[0;32m/usr/lib/python3.8/json/encoder.py:201\u001b[0m, in \u001b[0;36mJSONEncoder.encode\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/lib/python3.8/json/encoder.py?line=198'>199</a>\u001b[0m chunks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miterencode(o, _one_shot\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    <a href='file:///usr/lib/python3.8/json/encoder.py?line=199'>200</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(chunks, (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m)):\n\u001b[0;32m--> <a href='file:///usr/lib/python3.8/json/encoder.py?line=200'>201</a>\u001b[0m     chunks \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(chunks)\n\u001b[1;32m    <a href='file:///usr/lib/python3.8/json/encoder.py?line=201'>202</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(chunks)\n",
      "File \u001b[0;32m/usr/lib/python3.8/json/encoder.py:431\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/lib/python3.8/json/encoder.py?line=428'>429</a>\u001b[0m     \u001b[39myield from\u001b[39;00m _iterencode_list(o, _current_indent_level)\n\u001b[1;32m    <a href='file:///usr/lib/python3.8/json/encoder.py?line=429'>430</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(o, \u001b[39mdict\u001b[39m):\n\u001b[0;32m--> <a href='file:///usr/lib/python3.8/json/encoder.py?line=430'>431</a>\u001b[0m     \u001b[39myield from\u001b[39;00m _iterencode_dict(o, _current_indent_level)\n\u001b[1;32m    <a href='file:///usr/lib/python3.8/json/encoder.py?line=431'>432</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///usr/lib/python3.8/json/encoder.py?line=432'>433</a>\u001b[0m     \u001b[39mif\u001b[39;00m markers \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/lib/python3.8/json/encoder.py:405\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_dict\u001b[0;34m(dct, _current_indent_level)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/lib/python3.8/json/encoder.py?line=402'>403</a>\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///usr/lib/python3.8/json/encoder.py?line=403'>404</a>\u001b[0m             chunks \u001b[39m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[0;32m--> <a href='file:///usr/lib/python3.8/json/encoder.py?line=404'>405</a>\u001b[0m         \u001b[39myield from\u001b[39;00m chunks\n\u001b[1;32m    <a href='file:///usr/lib/python3.8/json/encoder.py?line=405'>406</a>\u001b[0m \u001b[39mif\u001b[39;00m newline_indent \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///usr/lib/python3.8/json/encoder.py?line=406'>407</a>\u001b[0m     _current_indent_level \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m/usr/lib/python3.8/json/encoder.py:405\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_dict\u001b[0;34m(dct, _current_indent_level)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/lib/python3.8/json/encoder.py?line=402'>403</a>\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///usr/lib/python3.8/json/encoder.py?line=403'>404</a>\u001b[0m             chunks \u001b[39m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[0;32m--> <a href='file:///usr/lib/python3.8/json/encoder.py?line=404'>405</a>\u001b[0m         \u001b[39myield from\u001b[39;00m chunks\n\u001b[1;32m    <a href='file:///usr/lib/python3.8/json/encoder.py?line=405'>406</a>\u001b[0m \u001b[39mif\u001b[39;00m newline_indent \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///usr/lib/python3.8/json/encoder.py?line=406'>407</a>\u001b[0m     _current_indent_level \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "    \u001b[0;31m[... skipping similar frames: _make_iterencode.<locals>._iterencode_dict at line 405 (3 times)]\u001b[0m\n",
      "File \u001b[0;32m/usr/lib/python3.8/json/encoder.py:405\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_dict\u001b[0;34m(dct, _current_indent_level)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/lib/python3.8/json/encoder.py?line=402'>403</a>\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///usr/lib/python3.8/json/encoder.py?line=403'>404</a>\u001b[0m             chunks \u001b[39m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[0;32m--> <a href='file:///usr/lib/python3.8/json/encoder.py?line=404'>405</a>\u001b[0m         \u001b[39myield from\u001b[39;00m chunks\n\u001b[1;32m    <a href='file:///usr/lib/python3.8/json/encoder.py?line=405'>406</a>\u001b[0m \u001b[39mif\u001b[39;00m newline_indent \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///usr/lib/python3.8/json/encoder.py?line=406'>407</a>\u001b[0m     _current_indent_level \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m/usr/lib/python3.8/json/encoder.py:438\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/lib/python3.8/json/encoder.py?line=435'>436</a>\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCircular reference detected\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    <a href='file:///usr/lib/python3.8/json/encoder.py?line=436'>437</a>\u001b[0m     markers[markerid] \u001b[39m=\u001b[39m o\n\u001b[0;32m--> <a href='file:///usr/lib/python3.8/json/encoder.py?line=437'>438</a>\u001b[0m o \u001b[39m=\u001b[39m _default(o)\n\u001b[1;32m    <a href='file:///usr/lib/python3.8/json/encoder.py?line=438'>439</a>\u001b[0m \u001b[39myield from\u001b[39;00m _iterencode(o, _current_indent_level)\n\u001b[1;32m    <a href='file:///usr/lib/python3.8/json/encoder.py?line=439'>440</a>\u001b[0m \u001b[39mif\u001b[39;00m markers \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/lib/python3.8/json/encoder.py:179\u001b[0m, in \u001b[0;36mJSONEncoder.default\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/lib/python3.8/json/encoder.py?line=159'>160</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdefault\u001b[39m(\u001b[39mself\u001b[39m, o):\n\u001b[1;32m    <a href='file:///usr/lib/python3.8/json/encoder.py?line=160'>161</a>\u001b[0m     \u001b[39m\"\"\"Implement this method in a subclass such that it returns\u001b[39;00m\n\u001b[1;32m    <a href='file:///usr/lib/python3.8/json/encoder.py?line=161'>162</a>\u001b[0m \u001b[39m    a serializable object for ``o``, or calls the base implementation\u001b[39;00m\n\u001b[1;32m    <a href='file:///usr/lib/python3.8/json/encoder.py?line=162'>163</a>\u001b[0m \u001b[39m    (to raise a ``TypeError``).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/lib/python3.8/json/encoder.py?line=176'>177</a>\u001b[0m \n\u001b[1;32m    <a href='file:///usr/lib/python3.8/json/encoder.py?line=177'>178</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> <a href='file:///usr/lib/python3.8/json/encoder.py?line=178'>179</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mObject of type \u001b[39m\u001b[39m{\u001b[39;00mo\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    <a href='file:///usr/lib/python3.8/json/encoder.py?line=179'>180</a>\u001b[0m                     \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mis not JSON serializable\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Object of type int64 is not JSON serializable"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open(\"EveryFileIndividually_Untuned_AllTestResults.json\", \"a\") as f:\n",
    "  f.write(json.dumps(OutputResults, indent=2))\n",
    "with open(\"EveryFileIndividually_Untuned_ModelResults.json\", \"a\") as f2:\n",
    "  f2.write(json.dumps(ModelResults, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"EveryFileIndividual_Untuned_ModelResults.csv\", \"w\") as f3:\n",
    "  f3.write(\"Test Size,Model,Accuracy,Runtime\\n\")\n",
    "  for size in ModelResults:\n",
    "    for model in ModelResults[size]:\n",
    "      f3.write(f\"{size},{model},{ModelResults[size][model]['Accuracy']},{ModelResults[size][model]['Runtime']}\\n\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

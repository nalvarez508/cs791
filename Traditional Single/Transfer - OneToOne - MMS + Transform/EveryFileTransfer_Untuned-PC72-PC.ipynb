{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traditional Methods trained on every file, tested on one at a time (untuned)\n",
    "MinMaxScaler is applied to these tests. All models are untuned. The model will be trained on file A, tested on files B,C,D.., then on B, tested on A,C,D.. etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "from time import process_time\n",
    "from os import listdir, chdir\n",
    "\n",
    "def warn(*args, **kwargs):\n",
    "  pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "\n",
    "from modules.NetworkTraffic import NetworkTraffic\n",
    "from sklearn import model_selection, metrics\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "FilesToTest = list()\n",
    "chdir(\"../../data\")\n",
    "for file in listdir():\n",
    "  if file.endswith(\".csv\"):\n",
    "    FilesToTest.append(file)\n",
    "\n",
    "TestSize = [0.4]\n",
    "ModelsToTest = [RandomForestClassifier(), GradientBoostingClassifier(), DecisionTreeClassifier(), MLPClassifier(), LinearSVC()]\n",
    "OutputResults = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel(model, x_train, y_train):\n",
    "  #print(f\"Testing {str(model)}\", end=', ')\n",
    "  start = process_time()\n",
    "\n",
    "  ### Begin timing\n",
    "  temp_clf = model\n",
    "  temp_clf.fit(x_train, y_train)\n",
    "\n",
    "  ### End timing\n",
    "\n",
    "  stop = process_time()\n",
    "  return [temp_clf, (stop-start)]\n",
    "\n",
    "\n",
    "def testModel(model, x_test, y_test, runtime):\n",
    "  y_pred = model.predict(x_test)\n",
    "  # Results\n",
    "  tempDict = {\n",
    "    \"Accuracy\": metrics.accuracy_score(y_test, y_pred),\n",
    "    \"Balanced Accuracy\": metrics.balanced_accuracy_score(y_test, y_pred),\n",
    "    \"F1 Micro\": metrics.f1_score(y_test, y_pred, average='micro'),\n",
    "    \"Precision Micro\": metrics.f1_score(y_test, y_pred, average='micro'),\n",
    "    \"Recall Micro\": metrics.recall_score(y_test, y_pred, average='micro'),\n",
    "    \"Runtime\": runtime,\n",
    "  }\n",
    "\n",
    "  return {str(model): tempDict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "FileObjects = dict()\n",
    "\n",
    "for file in FilesToTest:\n",
    "  FileObjects[file] = NetworkTraffic(file, testSize=0.4, doNorm=True, doNormAll=True, doTransform=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b5000d100.csv, [RandomForestClassifier(), GradientBoostingClassifier(), DecisionTreeClassifier(), MLPClassifier(), LinearSVC(), ]\n",
      "b5000d30.csv, [RandomForestClassifier(), GradientBoostingClassifier(), DecisionTreeClassifier(), MLPClassifier(), LinearSVC(), ]\n",
      "b100d10.csv, [RandomForestClassifier(), GradientBoostingClassifier(), DecisionTreeClassifier(), MLPClassifier(), LinearSVC(), ]\n",
      "b1000d10.csv, [RandomForestClassifier(), GradientBoostingClassifier(), DecisionTreeClassifier(), MLPClassifier(), LinearSVC(), ]\n",
      "b1000d100.csv, [RandomForestClassifier(), GradientBoostingClassifier(), DecisionTreeClassifier(), MLPClassifier(), LinearSVC(), ]\n",
      "b100d100.csv, [RandomForestClassifier(), GradientBoostingClassifier(), DecisionTreeClassifier(), MLPClassifier(), LinearSVC(), ]\n",
      "b5000d10.csv, [RandomForestClassifier(), GradientBoostingClassifier(), DecisionTreeClassifier(), MLPClassifier(), LinearSVC(), ]\n",
      "b1000d30.csv, [RandomForestClassifier(), GradientBoostingClassifier(), DecisionTreeClassifier(), MLPClassifier(), LinearSVC(), ]\n",
      "b100d30.csv, [RandomForestClassifier(), GradientBoostingClassifier(), DecisionTreeClassifier(), MLPClassifier(), LinearSVC(), ]\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "OutputResults.clear()\n",
    "\n",
    "for index, file in enumerate(FilesToTest):\n",
    "  print(file, end=', ')\n",
    "  OutputResults[file] = dict()\n",
    "  #currentFileData = NetworkTraffic(file, testSize=0.4, doNorm=True, doNormAll=True, doTransform=True)\n",
    "  currentFileData = FileObjects[file]\n",
    "  restOfFiles = deepcopy(FilesToTest)\n",
    "  restOfFiles.pop(index)\n",
    "  print('[', end='')\n",
    "  for model in ModelsToTest:\n",
    "    api, runtime = trainModel(model, currentFileData.data, currentFileData.target)\n",
    "    print(str(model), end=', ')\n",
    "    for file2 in restOfFiles:\n",
    "      #print(file2, end=' ')\n",
    "      OutputResults[file][file2] = dict()\n",
    "      #testFileData = NetworkTraffic(file2, testSize=0.4, doNorm=True, doNormAll=True, doTransform=True)\n",
    "      testFileData = FileObjects[file2]\n",
    "      x_test, y_test = testFileData.data, testFileData.target\n",
    "      results = testModel(api, x_test, y_test, runtime)\n",
    "      OutputResults[file][file2] = results\n",
    "  print(']')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"EveryFileTransfer_Untuned_AllTestResults.json\", \"w\") as f:\n",
    "  f.write(json.dumps(OutputResults, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"EveryFileTransfer_Untuned_ModelResults.csv\", \"w\") as f3:\n",
    "  f3.write(\"Trained On,Tested On,Model,Accuracy,Runtime\\n\")\n",
    "  for file in OutputResults:\n",
    "    for file2 in OutputResults[file]:\n",
    "      for model in OutputResults[file][file2]:\n",
    "        f3.write(f\"{file},{file2},{model},{OutputResults[file][file2][model]['Accuracy']},{OutputResults[file][file2][model]['Runtime']}\\n\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
